1. Open `malware_analysis.py` and run it

   1. we first use `x, y = read_dataset.read_data()`
      - which uses pandas to import the csv file of drebin dataset (download from [here](https://drive.google.com/file/d/0Bxxqx_AAp2u2enI0UzBqSEZQRHc/edit))
      - prints out the size of the dataset and classify if the file is malware or not based on if the file name is found in csv file or not, and prints number of malwares found and number of safe files
      - Extract features found in each file and if malware labels it 1, 0 otherwise
        - `sample = features_extraction.extract_features(file_content)`
          - uses method implemented in `features_extraction.py`
          - define a features set dictionary including all the features that can be used to detect a malware
          - the method `extract_features(file_content)` creates an empty dictionary to have the number of features occurrences in the input -which is a text file-
          - Whenever a feature extracted from file content, and this feature is found in the features set dictionary it increments its corresponding in the occurrences dictionary we created
          - in the end we copy the values of the dictionary to an array and return it
      - convert the arrays of feature vectors and labels to numpy arrays and return them in variables x & y
   2. And then we select the features we want for demonstration

      - basically all do the same thing in terms of coding them -not in terms of what happens under the hood-, we fit all the data in to get to know which features have the most impact on the models and thus we use them
        - `features_selection.select_features_k_best(x, y)`
          - scikit-learn library provides the SelectKBest class that can be used with a suite of different statistical tests to select a specific number of features.
          - uses the chi squared (chi^2) statistical test for non-negative features to select 4 of the best features from the dataset
        - `features_selection.select_features_recursive_feature_elimination(x, y)`
          - It works by recursively removing attributes and building a model on those attributes that remain.
          - It works by recursively removing attributes and building a model on those attributes that remain.
        - `features_selection.select_features_extra_trees(x, y)`
        - `features_selection.select_features_random_forest(x, y)`
          - both of random forest and extra trees, we can say they are approximately the same in terms of how they work
            Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance of features.

---

_Note_ that, the code balances the dataset based on the malware files size, you can change that by removing the part the states 'remove this for using unbalanced dataset' in read_dataset.py file

---

### Performance Metrices

- Accuracy

  - how many instances were classified correctly
  - (TP + TN) / (TP + FN + TN + FP)

- Precision:

  - It talks about how precise/accurate your model is out of those predicted positive, how many of them are actual positive.
  - It is a good measure to determine, when the costs of False Positive is high.
  - True positives per Total predicted positives (True Positive/ True Positive + False Positive)

- Recall

  - It actually calculates how many of the Actual Positives our model capture through labeling it as Positive (True Positive).
  - It shall be the model metric we use to select our best model when there is a high cost associated with False Negative.
  - True positives / True Positive + False Negative

- F1 Score
  - It might be a better measure to use if we need to seek a balance between Precision and Recall AND there is an uneven class distribution (large number of Actual Negatives)
  - 2 x ((Precision x Recall) / (Precision + Recall))

---
